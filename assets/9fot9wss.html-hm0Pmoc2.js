import{_ as i,c as a,a as t,o as e}from"./app-CS9K37Kg.js";const n={};function l(h,s){return e(),a("div",null,s[0]||(s[0]=[t(`<p><code>.gguf</code> 和 <code>safetensors</code> 是两种不同的模型权重文件格式，主要用于存储和加载大型机器学习模型。它们各自有一些特点和优势，下面将详细介绍这两种格式的区别：</p><h3 id="gguf-格式" tabindex="-1"><a class="header-anchor" href="#gguf-格式"><span><code>.gguf</code> 格式</span></a></h3><p><code>.gguf</code>（GPTQ-for-LLaMa Universal Format）是由 GPTQ-for-LLaMa 团队引入的一种轻量级、通用的模型文件格式，旨在简化大模型（如语言模型）的存储和加载过程。</p><h4 id="特点" tabindex="-1"><a class="header-anchor" href="#特点"><span>特点：</span></a></h4><ol><li><strong>轻量化</strong>：<code>.gguf</code> 格式设计上注重减少文件大小，提高传输效率。</li><li><strong>兼容性</strong>：目标是提供一种跨平台、跨框架的通用格式，使得不同工具和库能够更容易地加载相同的模型文件。</li><li><strong>易于使用</strong>：旨在简化用户操作流程，降低使用门槛。</li><li><strong>新出现</strong>：作为一个较新的格式，其生态系统和支持度可能还在发展中。</li></ol><h4 id="使用场景" tabindex="-1"><a class="header-anchor" href="#使用场景"><span>使用场景：</span></a></h4><ul><li>主要针对需要高效处理大型语言模型的应用场景。</li><li>对于希望在不同环境或框架之间轻松迁移模型的用户来说非常有用。</li></ul><h3 id="safetensors-格式" tabindex="-1"><a class="header-anchor" href="#safetensors-格式"><span><code>safetensors</code> 格式</span></a></h3><p><code>safetensors</code> 是由 Hugging Face 提出的一种安全、高效的张量存储格式。它被设计为 PyTorch 的 <code>.pt</code> 或 TensorFlow 的 <code>.ckpt</code> 文件的安全替代品。</p><h4 id="特点-1" tabindex="-1"><a class="header-anchor" href="#特点-1"><span>特点：</span></a></h4><ol><li><strong>安全性</strong>：避免了传统 pickle 格式的安全风险，因为它不执行任何代码即可加载数据。</li><li><strong>性能</strong>：相比传统的模型保存格式，<code>safetensors</code> 在加载速度上有显著提升。</li><li><strong>简单性</strong>：文件结构简单明了，便于理解和实现。</li><li><strong>广泛支持</strong>：由于 Hugging Face 的影响力，<code>safetensors</code> 已经得到了许多社区的支持，并且越来越多的工具和库开始支持这种格式。</li></ol><h4 id="使用场景-1" tabindex="-1"><a class="header-anchor" href="#使用场景-1"><span>使用场景：</span></a></h4><ul><li>适用于需要高效且安全地加载模型权重的情况。</li><li>当你需要在一个可信度较低的环境中加载模型时，<code>safetensors</code> 提供了额外的安全层。</li></ul><h3 id="比较与选择" tabindex="-1"><a class="header-anchor" href="#比较与选择"><span>比较与选择</span></a></h3><table><thead><tr><th>特性</th><th><code>.gguf</code></th><th><code>safetensors</code></th></tr></thead><tbody><tr><td><strong>主要用途</strong></td><td>大型语言模型的通用存储格式</td><td>安全高效的张量存储</td></tr><tr><td><strong>安全性</strong></td><td>不明确是否具有特定的安全特性</td><td>高，避免了pickle的安全隐患</td></tr><tr><td><strong>文件大小</strong></td><td>注重优化，通常较小</td><td>依赖于具体实现</td></tr><tr><td><strong>加载速度</strong></td><td>未详细说明，但作为优化目标之一</td><td>快</td></tr><tr><td><strong>跨平台/框架支持</strong></td><td>目标是高度兼容</td><td>良好，特别是在Hugging Face生态中</td></tr><tr><td><strong>社区支持</strong></td><td>新兴格式，支持正在增长</td><td>广泛支持</td></tr></tbody></table><h3 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h3><p>选择哪种格式取决于你的具体需求。如果你关注的是一个新兴的、专注于大型语言模型的通用解决方案，并且愿意探索和支持一个新的生态系统，那么 <code>.gguf</code> 可能是一个好的选择。另一方面，如果你更看重安全性、性能以及广泛的社区支持，<code>safetensors</code> 则是一个更加成熟和可靠的选择。</p><p>请根据你的项目需求、团队的技术栈偏好以及对安全性和性能的具体要求来做出最适合的选择。如果 Ollama 或其他相关平台推荐或特别支持某种格式，也应考虑这一点。</p><p>除了 <code>.gguf</code> 和 <code>safetensors</code> 格式之外，还有多种其他格式用于存储机器学习模型。每种格式都有其特定的用途、优点和适用场景。以下是几种常见的模型文件格式：</p><h3 id="_1-tensorflow-checkpoint-ckpt" tabindex="-1"><a class="header-anchor" href="#_1-tensorflow-checkpoint-ckpt"><span>1. <strong>TensorFlow Checkpoint (<code>.ckpt</code>)</strong></span></a></h3><ul><li><strong>描述</strong>: TensorFlow 使用的检查点格式，用于保存模型变量的状态。</li><li><strong>特点</strong>: 支持部分恢复（即可以只加载部分变量），适合训练过程中保存中间状态。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">saver </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> tf</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">train</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Saver</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">saver</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">sess</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.ckpt</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="_2-tensorflow-savedmodel" tabindex="-1"><a class="header-anchor" href="#_2-tensorflow-savedmodel"><span>2. <strong>TensorFlow SavedModel</strong></span></a></h3><ul><li><strong>描述</strong>: TensorFlow 推荐的标准格式，支持跨平台部署，适用于生产环境。</li><li><strong>特点</strong>: 包含了计算图和权重，支持版本控制和服务化。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tf</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">saved_model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">saved_model_dir</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><h3 id="_3-pytorch-state-dict-pt-或-pth" tabindex="-1"><a class="header-anchor" href="#_3-pytorch-state-dict-pt-或-pth"><span>3. <strong>PyTorch State Dict (<code>.pt</code> 或 <code>.pth</code>)</strong></span></a></h3><ul><li><strong>描述</strong>: PyTorch 中最常用的模型保存方式之一，保存的是模型的状态字典（state dict）。</li><li><strong>特点</strong>: 只保存模型参数，不包含计算图结构，适合在相同架构下加载。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">state_dict</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.pth</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><h3 id="_4-onnx-open-neural-network-exchange" tabindex="-1"><a class="header-anchor" href="#_4-onnx-open-neural-network-exchange"><span>4. <strong>ONNX (Open Neural Network Exchange)</strong></span></a></h3><ul><li><strong>描述</strong>: 一种开放标准，旨在使不同框架之间的模型能够互相转换和使用。</li><li><strong>特点</strong>: 支持多框架互操作性，便于部署到各种硬件和平台上。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">onnx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">export</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> dummy_input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.onnx</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><h3 id="_5-keras-hdf5-h5" tabindex="-1"><a class="header-anchor" href="#_5-keras-hdf5-h5"><span>5. <strong>Keras HDF5 (<code>.h5</code>)</strong></span></a></h3><ul><li><strong>描述</strong>: Keras 模型的一种常见保存格式，基于 HDF5 文件格式。</li><li><strong>特点</strong>: 同时保存模型架构和权重，易于加载。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.h5</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><h3 id="_6-pmml-predictive-model-markup-language" tabindex="-1"><a class="header-anchor" href="#_6-pmml-predictive-model-markup-language"><span>6. <strong>PMML (Predictive Model Markup Language)</strong></span></a></h3><ul><li><strong>描述</strong>: XML 格式的标准，用于表示预测模型，广泛应用于传统数据分析领域。</li><li><strong>特点</strong>: 高度可移植，但对深度学习模型的支持有限。</li><li><strong>使用示例</strong>: 通常通过第三方库如 JPMML 转换。</li></ul><h3 id="_7-pickle-pkl" tabindex="-1"><a class="header-anchor" href="#_7-pickle-pkl"><span>7. <strong>Pickle (<code>.pkl</code>)</strong></span></a></h3><ul><li><strong>描述</strong>: Python 的序列化模块，可用于保存任何Python对象，包括模型。</li><li><strong>特点</strong>: 简单易用，但存在安全风险（可能执行恶意代码）。</li><li><strong>使用示例</strong>:<div class="language-python line-numbers-mode" data-ext="python" data-title="python"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> pickle</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">with</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> open</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.pkl</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">wb</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;"> as</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> f</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    pickle</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">dump</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> f</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="_8-marianmt-model" tabindex="-1"><a class="header-anchor" href="#_8-marianmt-model"><span>8. <strong>MarianMT Model</strong></span></a></h3><ul><li><strong>描述</strong>: 特定于 Marian NMT 框架的模型格式。</li><li><strong>特点</strong>: 主要用于神经机器翻译任务，具有高效的推断性能。</li></ul><h3 id="_9-core-ml-model-mlmodel" tabindex="-1"><a class="header-anchor" href="#_9-core-ml-model-mlmodel"><span>9. <strong>Core ML Model (<code>.mlmodel</code>)</strong></span></a></h3><ul><li><strong>描述</strong>: Apple 提供的一种格式，专门用于 iOS 应用中的机器学习模型。</li><li><strong>特点</strong>: 支持将多种框架的模型转换为 Core ML 格式，便于集成到苹果生态系统中。</li></ul><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><p>不同的模型文件格式服务于不同的需求和场景。选择合适的格式取决于多个因素，包括但不限于：</p><ul><li>模型的框架（如 TensorFlow, PyTorch）</li><li>是否需要跨框架兼容性</li><li>对安全性、效率和易用性的要求</li><li>目标部署环境（如服务器、移动设备）</li></ul><p>了解这些格式的特点有助于更好地管理和部署你的机器学习模型。如果你有特定的需求或遇到问题，深入研究相关框架的文档或者社区讨论也会很有帮助。</p>`,41)]))}const d=i(n,[["render",l],["__file","9fot9wss.html.vue"]]),o=JSON.parse('{"path":"/llm/models/9fot9wss.html","title":"模型的保存格式","lang":"zh-CN","frontmatter":{"title":"模型的保存格式","createTime":"2025/02/08 10:42:57","permalink":"/llm/models/9fot9wss.html","watermark":true},"headers":[],"readingTime":{"minutes":5.49,"words":1647},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/models/模型的保存格式.md","bulletin":false}');export{d as comp,o as data};
