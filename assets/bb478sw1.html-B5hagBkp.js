import{_ as r,c as o,a,o as t}from"./app-CS9K37Kg.js";const n={};function c(h,e){return t(),o("div",null,e[0]||(e[0]=[a('<p>PyTorch 是一个 Python 软件包，其提供了两种高层面的功能：</p><ul><li>使用强大的 GPU 加速的 Tensor 计算（类似 numpy）</li><li>构建于基于 tape 的 autograd 系统的深度神经网络</li></ul><p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够 实现强大的GPU加速，同时还支持动态神经网络，这一点是现在很多主流框架如TensorFlow都不支持的。</p><p>PyTorch提供了两个高级功能：</p><p>1.具有强大的GPU加速的张量计算（如Numpy） 2.包含自动求导系统的深度神经网络 除了Facebook之外，Twitter、GMU和Salesforce等机构都采用了PyTorch。</p><p><strong>TensorFlow和Caffe都是命令式的编程语言，而且是静态的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改变网络的结构，就必须从头开始</strong>。但是对于PyTorch，通过反向求导技术，可以让你零延迟地任意改变神经网络的行为，而且其实现速度 快。正是这一灵活性是PyTorch对比TensorFlow的最大优势。</p><p>当然，现今任何一个深度学习框架都有其缺点，PyTorch也不例外，对比TensorFlow，其全面性处于劣势，目前PyTorch还不支持快速傅里 叶、沿维翻转张量和检查无穷与非数值张量；针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；其次因为这个框 架较新，使得他的社区没有那么强大，在文档方面其C库大多数没有文档。</p><h2 id="基础知识" tabindex="-1"><a class="header-anchor" href="#基础知识"><span>基础知识</span></a></h2><h3 id="tensor" tabindex="-1"><a class="header-anchor" href="#tensor"><span>Tensor</span></a></h3><p>Tensor（张量）是PyTorch中的基本数据结构，类似于NumPy中的ndarray，但Tensor可以在GPU上运行，并且支持自动求导。PyTorch中的张量支持各种操作，如加法、减法、乘法、除法、指数运算、对数运算、矩阵乘法、转置、切片、拼接等。</p><p><code>torch.Tensor</code> 是包的核心类。如果将其属性 <code>.requires_grad</code> 设置为 True，则会开始跟踪针对 tensor 的所有操作。完成计算后，您可以调用 <code>.backward()</code> 来自动计算所有梯度。该张量的梯度将累积到 <code>.grad</code> 属性中。</p><p>要停止 tensor 历史记录的跟踪，您可以调用 <code>.detach()</code>，它将其与计算历史记录分离，并防止将来的计算被跟踪。</p><p>要停止跟踪历史记录（和使用内存），您还可以将代码块使用 <code>with torch.no_grad()</code>: 包装起来。在评估模型时，这是特别有用，因为模型在训练阶段具有 <code>requires_grad = True</code> 的可训练参数有利于调参，但在评估阶段我们不需要梯度。</p><p>还有一个类对于 autograd 实现非常重要那就是 Function。Tensor 和 Function 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。每个张量都有一个 <code>.grad_fn</code> 属性保存着创建了张量的 Function 的引用，（如果用户自己创建张量，则gfrad_fn 是 None。</p><p>如果你想计算导数，你可以调用 <code>Tensor.backward()</code>。如果 Tensor 是标量（即它包含一个元素数据），则不需要指定任何参数<code>backward()</code>，但是如果它有更多元素，则需要指定一个gradient 参数来指定张量的形状。</p><h3 id="autograd" tabindex="-1"><a class="header-anchor" href="#autograd"><span>Autograd</span></a></h3><p>Autograd是PyTorch中的自动求导系统，它能够自动计算梯度，使得训练神经网络变得更加简单。Autograd支持所有Tensor操作，并且可以自动计算梯度，无需手动编写梯度计算代码。</p><h3 id="神经网络" tabindex="-1"><a class="header-anchor" href="#神经网络"><span>神经网络</span></a></h3><p>神经网络可以通过 torch.nn 包来构建。现在对于自动梯度(autograd)有一些了解，神经网络是基于自动梯度 (autograd)来定义一些模型。一个 nn.Module 包括层和一个方法 <code>forward(input)</code> 它会返回输出(output)。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><p><a href="https://pytorch.org/index.html" target="_blank" rel="noopener noreferrer">PyTorch</a></p><p><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">GitHub PyTorch</a></p><p><a href="https://hellowac.github.io/uv-zh-cn/guides/integration/pytorch/" target="_blank" rel="noopener noreferrer">uv 使用文档</a></p><p><a href="https://www.pytorch123.com/" target="_blank" rel="noopener noreferrer">PyTorch 中文教程</a></p>',24)]))}const p=r(n,[["render",c],["__file","bb478sw1.html.vue"]]),s=JSON.parse('{"path":"/ai/bb478sw1.html","title":"PyTorch","lang":"zh-CN","frontmatter":{"title":"PyTorch","createTime":"2025/03/25 16:51:32","permalink":"/ai/bb478sw1.html","watermark":true},"headers":[],"readingTime":{"minutes":3.54,"words":1063},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/ai/pytorch/PyTorch.md","bulletin":false}');export{p as comp,s as data};
