import{_ as t,c as o,a,o as n}from"./app-CS9K37Kg.js";const r={};function p(k,e){return n(),o("div",null,e[0]||(e[0]=[a('<h1 id="tokenizer" tabindex="-1"><a class="header-anchor" href="#tokenizer"><span>tokenizer</span></a></h1><p>tiktoken是OpenAI开源的一个快速分词工具。它将一个文本字符串（例如“tiktoken很棒！”）和一个编码（例如“cl100k_base”）作为输入，然后将字符串拆分为标记列表（例如[&quot;t&quot;，&quot;ik&quot;，&quot;token&quot;，&quot; is&quot;，&quot; great&quot;，&quot;!&quot;]）。</p><p>将文本字符串拆分成tokens是有价值的，因为GPT模型使用tokens表示文本。了解文本字符串中有多少tokens可以告诉我们：</p><p>该字符串是否太长以至于文本模型无法处理； OpenAI API调用的费用（因为使用费用按token计算）。</p><p>语言分词库 对于cl100k_base和p50k_base编码：</p><p>Python：tiktoken .NET / C#：SharpToken，TiktokenSharp Java：jtokkit 对于r50k_base（gpt2）编码，许多语言都提供了分词库。</p><p>Python：tiktoken（或GPT2TokenizerFast） JavaScript：gpt-3-encoder .NET / C#：GPT Tokenizer Java：gpt2-tokenizer-java PHP：GPT-3-Encoder-PHP</p><p><a href="https://zhuanlan.zhihu.com/p/629776230" target="_blank" rel="noopener noreferrer">ChatGPT丨使用tiktoken计算tokens</a></p><p><a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">chatGPT tokenizer</a></p><p><a href="https://zhuanlan.zhihu.com/p/626080766" target="_blank" rel="noopener noreferrer">【OpenLLM 008】大模型基础组件之分词器-万字长文全面解读LLM中的分词算法与分词器（tokenization &amp; tokenizers）：BPE/WordPiece/ULM &amp; beyond</a></p>',10)]))}const s=t(r,[["render",p],["__file","knkktgpz.html.vue"]]),l=JSON.parse('{"path":"/llm/models/knkktgpz.html","title":"分词器","lang":"zh-CN","frontmatter":{"title":"分词器","createTime":"2025/01/20 18:02:38","permalink":"/llm/models/knkktgpz.html","watermark":true},"headers":[],"readingTime":{"minutes":0.97,"words":291},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/models/分词器.md","bulletin":false}');export{s as comp,l as data};
