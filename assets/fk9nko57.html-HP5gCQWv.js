import{_ as a,c as n,a as r,o as p}from"./app-CS9K37Kg.js";const o={};function h(s,e){return p(),n("div",null,e[0]||(e[0]=[r('<p><code>LLM</code>即大语言模型（<code>Large Language Model</code>）是指使用大量文本数据训练的深度学习模型，使得该模型可以生成自然语言文本或理解语言文本的含义。这些模型可以通过在庞大的数据集上进行训练来提供有关各种主题的深入知识和语言生产。其核心思想是通过大规模的无监督训练学习自然语言的模式和结构，在一定程度上模拟人类的语言认知和生成过程。</p><h2 id="chat" tabindex="-1"><a class="header-anchor" href="#chat"><span>Chat</span></a></h2><h3 id="openai-chat" tabindex="-1"><a class="header-anchor" href="#openai-chat"><span>OpenAI Chat</span></a></h3><p><a href="https://chatgpt.com/" target="_blank" rel="noopener noreferrer">ChatGPT</a></p><h3 id="gemini" tabindex="-1"><a class="header-anchor" href="#gemini"><span>Gemini</span></a></h3><p><a href="https://gemini.google.com/app" target="_blank" rel="noopener noreferrer">Gemini</a></p><h3 id="deepseek-chat" tabindex="-1"><a class="header-anchor" href="#deepseek-chat"><span>DeepSeek Chat</span></a></h3><p><a href="https://chat.deepseek.com/" target="_blank" rel="noopener noreferrer">deepseek Chat</a></p><h3 id="通义千问" tabindex="-1"><a class="header-anchor" href="#通义千问"><span>通义千问</span></a></h3><p><a href="https://tongyi.aliyun.com/qianwen/" target="_blank" rel="noopener noreferrer">通义千问</a></p><h3 id="文心一言" tabindex="-1"><a class="header-anchor" href="#文心一言"><span>文心一言</span></a></h3><p><a href="https://yiyan.baidu.com/" target="_blank" rel="noopener noreferrer">文心一言</a></p><h3 id="智谱青言" tabindex="-1"><a class="header-anchor" href="#智谱青言"><span>智谱青言</span></a></h3><p><a href="https://chatglm.cn/main/alltoolsdetail?lang=zh" target="_blank" rel="noopener noreferrer">智谱青言</a></p><h3 id="豆包" tabindex="-1"><a class="header-anchor" href="#豆包"><span>豆包</span></a></h3><p><a href="https://www.doubao.com/chat/" target="_blank" rel="noopener noreferrer">豆包</a></p><h3 id="kimi" tabindex="-1"><a class="header-anchor" href="#kimi"><span>Kimi</span></a></h3><p><a href="https://kimi.moonshot.cn/" target="_blank" rel="noopener noreferrer">Kimi</a></p><h3 id="纳米ai搜索" tabindex="-1"><a class="header-anchor" href="#纳米ai搜索"><span>纳米AI搜索</span></a></h3><p><a href="https://www.n.cn/?fromsou=1" target="_blank" rel="noopener noreferrer">纳米AI搜索</a></p><h2 id="绘图" tabindex="-1"><a class="header-anchor" href="#绘图"><span>绘图</span></a></h2><h3 id="midjourney" tabindex="-1"><a class="header-anchor" href="#midjourney"><span>Midjourney</span></a></h3><h3 id="dall-e" tabindex="-1"><a class="header-anchor" href="#dall-e"><span>Dall.E</span></a></h3><h2 id="音乐" tabindex="-1"><a class="header-anchor" href="#音乐"><span>音乐</span></a></h2><h3 id="suno" tabindex="-1"><a class="header-anchor" href="#suno"><span>Suno</span></a></h3><h3 id="udio" tabindex="-1"><a class="header-anchor" href="#udio"><span>Udio</span></a></h3><h2 id="视频" tabindex="-1"><a class="header-anchor" href="#视频"><span>视频</span></a></h2><h3 id="luma" tabindex="-1"><a class="header-anchor" href="#luma"><span>Luma</span></a></h3><h3 id="runway" tabindex="-1"><a class="header-anchor" href="#runway"><span>Runway</span></a></h3><h3 id="pika" tabindex="-1"><a class="header-anchor" href="#pika"><span>Pika</span></a></h3><h2 id="llm-开放平台" tabindex="-1"><a class="header-anchor" href="#llm-开放平台"><span>LLM 开放平台</span></a></h2><h3 id="openai" tabindex="-1"><a class="header-anchor" href="#openai"><span>OpenAI</span></a></h3><p>现在大模型的标杆，模型能力很强，功能也比较稳定。</p><ul><li>服务器在国外，需要代理才行</li><li>API收费比较贵，阶梯收费</li></ul><p><a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">OpenAI 文档</a></p><p><strong>提示</strong> 目前我们公司是通过专线转到国外的服务器使用的。国内直接使用账号可能会被封掉</p><h3 id="gemini-1" tabindex="-1"><a class="header-anchor" href="#gemini-1"><span>Gemini</span></a></h3><p><a href="https://deepmind.google/" target="_blank" rel="noopener noreferrer">deepmind</a></p><h3 id="claude" tabindex="-1"><a class="header-anchor" href="#claude"><span>Claude</span></a></h3><p><a href="https://docs.anthropic.com/zh-CN/docs/welcome" target="_blank" rel="noopener noreferrer">Claude 文档</a></p><h3 id="azure-openai" tabindex="-1"><a class="header-anchor" href="#azure-openai"><span>Azure OpenAI</span></a></h3><p>这是国内访问OpenAI的一个解决方案，需要公司开通Azure服务，且模型的更新稍慢</p><p><a href="https://learn.microsoft.com/zh-tw/azure/ai-services/openai/" target="_blank" rel="noopener noreferrer">Azure OpenAI</a></p><h3 id="deepseek" tabindex="-1"><a class="header-anchor" href="#deepseek"><span>DeepSeek</span></a></h3><p><strong>开源</strong><strong>兼容 OpenAI API</strong></p><p>国内模型，无需代理即可使用，能力也强，各种量化版本都有，一些版本本地部署都可以。</p><ul><li>一些功能还需要完善，比如：<a href="https://api-docs.deepseek.com/zh-cn/guides/function_calling" target="_blank" rel="noopener noreferrer">当前版本 deepseek-chat 模型 Function Calling 功能效果不稳定，会出现循环调用、空回复的情况。我们正在积极修复中，预计将在下一个版本中得到修复</a></li><li>当前服务器资源紧张（也可能是受攻击比较严重），已暂停 API 服务充值。</li></ul><p><a href="https://api-docs.deepseek.com/zh-cn" target="_blank" rel="noopener noreferrer">DeepSeek 文档</a></p><h3 id="通义千问-1" tabindex="-1"><a class="header-anchor" href="#通义千问-1"><span>通义千问</span></a></h3><p><strong>开源</strong><strong>兼容 OpenAI API</strong></p><p>能力是国产模型中比较强的。我们需要用到<code>Function Calling</code>经过测试，通义千问的这方面能力还是可以的。</p><p><a href="https://www.aliyun.com" target="_blank" rel="noopener noreferrer">阿里云</a></p><p><strong>提示</strong> 我们公司的AI产品，如果需要国产的话，基本是<strong>通义千问</strong>和<strong>智谱</strong>二选一。</p><h3 id="智谱ai" tabindex="-1"><a class="header-anchor" href="#智谱ai"><span>智谱AI</span></a></h3><p><strong>开源</strong><strong>兼容 OpenAI API</strong></p><p>也是比较强的国产模型。<code>Function Calling</code>能力比<strong>通义千问</strong>差一点儿，特别是填参格式需要简单处理一下，也存在填参截断的情况，之前提过工单，知道现在解决没有。</p><p><a href="https://open.bigmodel.cn/" target="_blank" rel="noopener noreferrer">智谱AI</a></p><p><strong>提示</strong> 我们公司的AI产品，如果需要国产的话，基本是<strong>通义千问</strong>和<strong>智谱</strong>二选一。</p><h3 id="月之暗面" tabindex="-1"><a class="header-anchor" href="#月之暗面"><span>月之暗面</span></a></h3><p><strong>兼容 OpenAI API</strong></p><p>能力还是可以，目前国内最大的上下文支持。之前用来做文本上传及内容检索，随着各家模型的上下文支持的不断提升，优势在减少。且RAG的发展对其也有一定的影响。</p><p><a href="https://www.moonshot.cn/" target="_blank" rel="noopener noreferrer">moonshot</a></p><h3 id="豆包-1" tabindex="-1"><a class="header-anchor" href="#豆包-1"><span>豆包</span></a></h3><p><strong>兼容 OpenAI API</strong></p><p>之前测试，<code>Function Calling</code>能力一般，存在循环调用的情况。</p><p><a href="https://www.volcengine.com/product/doubao" target="_blank" rel="noopener noreferrer">豆包大模型</a></p><h3 id="百度千帆" tabindex="-1"><a class="header-anchor" href="#百度千帆"><span>百度千帆</span></a></h3><p>模型还可以，但是<code>Function Calling</code>能力一般，<code>API</code>自成一派，上下文长度支持也不高。</p><p><a href="https://cloud.baidu.com" target="_blank" rel="noopener noreferrer">百度云</a></p><h2 id="llm-服务提供商" tabindex="-1"><a class="header-anchor" href="#llm-服务提供商"><span>LLM 服务提供商</span></a></h2><h3 id="nim" tabindex="-1"><a class="header-anchor" href="#nim"><span>NIM</span></a></h3><p>NVIDIA 的 NIM（NVIDIA Inference Microservices） 平台提供了 DeepSeek 模型的 API 支持。NVIDIA NIM 是一个高性能的推理服务平台，专为优化大模型的部署和推理而设计。通过 NVIDIA NIM，用户可以更高效地部署和管理 DeepSeek 模型。</p><p><a href="https://www.nvidia.com/en-in/ai/" target="_blank" rel="noopener noreferrer">NIM</a></p><p><a href="https://build.nvidia.com/explore/discover?ncid=no-ncid" target="_blank" rel="noopener noreferrer">NIM 文档</a></p><h3 id="硅基流动" tabindex="-1"><a class="header-anchor" href="#硅基流动"><span>硅基流动</span></a></h3><p><a href="https://account.siliconflow.cn" target="_blank" rel="noopener noreferrer">硅基流动</a></p><h3 id="派欧算力" tabindex="-1"><a class="header-anchor" href="#派欧算力"><span>派欧算力</span></a></h3><p>比硅基流动速度略快</p><p><a href="https://ppinfra.com" target="_blank" rel="noopener noreferrer">派欧算力</a></p><h3 id="无问芯穹" tabindex="-1"><a class="header-anchor" href="#无问芯穹"><span>无问芯穹</span></a></h3><p><a href="https://cloud.infini-ai.com" target="_blank" rel="noopener noreferrer">无问芯穹</a></p><h3 id="apishop" tabindex="-1"><a class="header-anchor" href="#apishop"><span>APIShop</span></a></h3><p>小网站</p><p><a href="https://my.apishop.cc/models" target="_blank" rel="noopener noreferrer">APIShop</a></p><h2 id="llm-社区" tabindex="-1"><a class="header-anchor" href="#llm-社区"><span>LLM 社区</span></a></h2><h3 id="魔搭社区" tabindex="-1"><a class="header-anchor" href="#魔搭社区"><span>魔搭社区</span></a></h3><p>中国版的<strong>Hugging Face</strong>，模型丰富，国内访问特别快</p><p><a href="https://modelscope.cn/" target="_blank" rel="noopener noreferrer">Model Scope</a></p><p><strong>提示</strong> 建议优先在这上面下载模型</p><h3 id="hugging-face" tabindex="-1"><a class="header-anchor" href="#hugging-face"><span>Hugging Face</span></a></h3><p>丰富的模型库，但国内访问较慢</p><p><a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face</a></p><p><strong>提示</strong> 建议使用代理下载模型</p>',93)]))}const i=a(o,[["render",h],["__file","fk9nko57.html.vue"]]),l=JSON.parse('{"path":"/llm/fk9nko57.html","title":"LLM 介绍","lang":"zh-CN","frontmatter":{"title":"LLM 介绍","createTime":"2025/02/10 15:51:59","permalink":"/llm/fk9nko57.html","watermark":true},"headers":[],"readingTime":{"minutes":3.67,"words":1100},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/LLM介绍.md","bulletin":false}');export{i as comp,l as data};
