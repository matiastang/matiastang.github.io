import{_ as r,c as a,a as t,o as s}from"./app-CS9K37Kg.js";const n={};function o(p,e){return s(),a("div",null,e[0]||(e[0]=[t('<p>KTransformers（Quick Transformers）一款由清华大学 MADSys 和 Approaching.AI 专为优化大模型本地推理体验而设计的开源框架。旨在通过高级内核优化和布局/并行策略来增强您的 Transformer 体验。</p><p>KTransformers 是一个灵活的、以 Python 为中心的框架，其设计以可扩展性为核心。通过使用单行代码实现和注入优化的模块，用户可以访问与 Transformers 兼容的界面、符合 OpenAI 和 Ollama 的 RESTful API，甚至是简化的类似 ChatGPT 的 Web UI。</p><p><img src="https://github.com/user-attachments/assets/6b4c1e54-9f6d-45c5-a3fc-8fa45e7d257e" alt="KTransformers 框架"></p><h2 id="服务" tabindex="-1"><a class="header-anchor" href="#服务"><span>服务</span></a></h2><p>KTransformers 专注于优化大模型的本地推理体验。它通过先进的内核优化和灵活的硬件配置策略，让开发者能够在有限的资源下实现高效的模型推理，并提供了与 Transformers 兼容的接口、符合 OpenAI 和 Ollama 标准的 RESTful API。</p><p><img src="https://kvcache-ai.github.io/ktransformers/en/api/server/server-arch.png" alt="后端服务"></p><h2 id="应用" tabindex="-1"><a class="header-anchor" href="#应用"><span>应用</span></a></h2><h3 id="本地运行-671b-deepseek-coder-v3-r1" tabindex="-1"><a class="header-anchor" href="#本地运行-671b-deepseek-coder-v3-r1"><span>本地运行 671B DeepSeek-Coder-V3/R1</span></a></h3><p>本地运行 671B DeepSeek-Coder-V3/R1：仅使用 14GB VRAM 和 382GB DRAM 运行其 Q4_K_M 版本（<a href="https://github.com/kvcache-ai/ktransformers/blob/main/doc/en/DeepseekR1_V3_tutorial.md" target="_blank" rel="noopener noreferrer">教程</a>）。</p><p>本地运行 236B DeepSeek-Coder-V2：仅使用 21GB VRAM 和 136GB DRAM 运行其 Q4_K_M 版本，可在本地台式机上实现，其得分甚至高于 <a href="https://bigcode-bench.github.io/" target="_blank" rel="noopener noreferrer">GitHub Pages</a> 中的 GPT4-0613。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><p><a href="https://github.com/kvcache-ai/ktransformers" target="_blank" rel="noopener noreferrer">GitHub ktransformers</a></p><p><a href="https://bigcode-bench.github.io/" target="_blank" rel="noopener noreferrer">GitHub Pages</a></p><p><a href="https://github.com/kvcache-ai/ktransformers/blob/main/doc/en/DeepseekR1_V3_tutorial.md" target="_blank" rel="noopener noreferrer">671B DeepSeek-Coder-V3/R1教程</a></p><p><a href="https://kvcache-ai.github.io/ktransformers/" target="_blank" rel="noopener noreferrer">ktransformers 文档</a></p>',15)]))}const h=r(n,[["render",o],["__file","92niv85w.html.vue"]]),m=JSON.parse('{"path":"/llm/ktransformers/92niv85w.html","title":"ktransformers 框架","lang":"zh-CN","frontmatter":{"title":"ktransformers 框架","createTime":"2025/02/20 09:24:03","permalink":"/llm/ktransformers/92niv85w.html","watermark":true},"headers":[],"readingTime":{"minutes":1.29,"words":386},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/ktransformers/ktransformers框架.md","bulletin":false}');export{h as comp,m as data};
