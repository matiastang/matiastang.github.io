import{_ as e,c as l,b as s,d as a,e as t,f as h,a as p,r as d,o as r}from"./app-CS9K37Kg.js";const o="/notes/llm/anythingllm/AnythingLLM%E4%B8%8B%E8%BD%BD.png",k="/notes/llm/anythingllm/AnythingLLM%E5%90%AF%E5%8A%A8.jpg",c="/notes/llm/anythingllm/AnythingLLM%E5%BC%80%E5%A7%8B.jpg",g="/notes/llm/anythingllm/AnythingLLM%E6%AD%A5%E9%AA%A4%E4%B8%80.jpg",A="/notes/llm/anythingllm/AnythingLLM%E6%AD%A5%E9%AA%A4%E4%BA%8C.jpg",m="/notes/llm/anythingllm/AnythingLLM%E6%AD%A5%E9%AA%A4%E4%B8%89.jpg",y="/notes/llm/anythingllm/AnythingLLM%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4.jpg",B="/notes/llm/anythingllm/AnythingLLM%E8%AE%BE%E7%BD%AE.jpg",L="/notes/llm/anythingllm/AnythingLLM%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B.jpg",C="/notes/llm/anythingllm/AnythingLLM%E8%AE%BE%E7%BD%AEEmbedder.jpg",b="/notes/llm/anythingllm/AnythingLLM%E5%B7%A5%E4%BD%9C%E5%8C%BA%E8%81%8A%E5%A4%A9%E8%AE%BE%E7%BD%AE.jpg",E="/notes/llm/anythingllm/AnythingLLM%E5%B7%A5%E4%BD%9C%E5%8C%BA%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE.jpg",u="/notes/llm/anythingllm/AnythingLLM%E6%96%B0%E5%BB%BA%E7%BA%BF%E7%A8%8B.jpg",v="/notes/llm/anythingllm/AnythingLLM%E8%BF%9B%E5%85%A5%E4%B8%8A%E4%BC%A0.jpg",M="/notes/llm/anythingllm/AnythingLLM%E6%B5%8B%E8%AF%95.jpg",D={};function f(x,i){const n=d("RouteLink");return r(),l("div",null,[i[2]||(i[2]=s("p",null,[a("使用"),s("code",null,"AnythingLLM"),a("接入"),s("code",null,"RAG"),a("，需要使用"),s("code",null,"Ollama"),a("本地运行模型，"),s("code",null,"nomic-embed-text"),a("作为嵌入模型。")],-1)),i[3]||(i[3]=s("h2",{id:"安装ollama",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#安装ollama"},[s("span",null,"安装Ollama")])],-1)),s("p",null,[i[1]||(i[1]=a("本地安装Ollama参考")),t(n,{to:"/notes/llm/ollama/oodx3ekp.html"},{default:h(()=>i[0]||(i[0]=[a("Ollama 使用")])),_:1})]),i[4]||(i[4]=p(`<h2 id="下载nomic-embed-text" tabindex="-1"><a class="header-anchor" href="#下载nomic-embed-text"><span>下载<code>nomic-embed-text</code></span></a></h2><p><code>nomic-embed-text</code>‌是一个完全开源的文本嵌入模型，由Nomic团队发布。该模型的主要特点是其在处理短文和长文本任务方面超越了现有的模型，如OpenAI的<code>Ada-002</code>和<code>text-embedding-3-small</code>。<code>nomic-embed-text</code>的上下文长度为8192，参数数量为137M，这使得它在处理长文本时表现出色‌。</p><p><code>nomic-embed-text-v1.5</code>是<code>Nomic Embed</code>的改进版本，利用了<code>Matryoshka</code>表示学习，允许在嵌入大小与性能之间灵活权衡。通过引入<code>Matryoshka</code>表示学习，该项目在提高嵌入质量的同时，提供了更大的嵌入尺寸和序列长度。</p><p>使用Ollama下载<code>nomic-embed-text</code></p><div class="language-sh line-numbers-mode" data-ext="sh" data-title="sh"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">$</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> pull</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> nomic-embed-text</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果直接使用Ollama下载<code>nomic-embed-text</code>比较慢，可以选择使用<code>ModelScope</code>社区中的模型。具体使用参考<a href="https://modelscope.cn/docs/models/advanced-usage/ollama-integration" target="_blank" rel="noopener noreferrer">Ollama加载ModelScope模型</a></p><p>我是直接下载的<code>ModelScope</code>中的模型</p><div class="language-sh line-numbers-mode" data-ext="sh" data-title="sh"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">$</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> pull</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> modelscope.cn/Embedding-GGUF/nomic-embed-text-v1.5-GGUF</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> manifest</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> d4e388894e09...</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 100%</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ▕█████████████████████████████████████████████████████████████████████▏</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  84</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> MB</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 885769ff7150...</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 100%</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ▕█████████████████████████████████████████████████████████████████████▏</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">   17</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> B</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> c71d239df917...</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 100%</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ▕█████████████████████████████████████████████████████████████████████▏</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  11</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> KB</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pulling</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 8ad2be369ff9...</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 100%</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ▕█████████████████████████████████████████████████████████████████████▏</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  205</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> B</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">verifying</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> sha256</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> digest</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">writing</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> manifest</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">success</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>注意</strong> 有一点儿需要注意的是，默认下载的是<code>Q4_K_M</code>版的模型</p><h2 id="anythingllm" tabindex="-1"><a class="header-anchor" href="#anythingllm"><span>AnythingLLM</span></a></h2><p>AnythingLLM 是由 Mintplex Labs 开发的开源 AI 工具，可以将任何东西转换为您可以查询和聊天的训练有素的聊天机器人。AnythingLLM 是一款 BYOK（自带密钥）软件，因此除了您想使用的服务外，此软件不收取订阅费、费用或其他费用。</p><p>AnythingLLM 是将强大的 AI 产品（如 OpenAi、GPT-4、LangChain、PineconeDB、ChromaDB 等）整合在一个整洁的包中而无需繁琐操作的最简单方法，可以将您的生产力提高 100 倍。</p><p>AnythingLLM 可以完全在您的本地计算机上运行，几乎没有开销，您甚至不会注意到它的存在！无需 GPU。也可以进行云端和本地安装。 AI 工具生态系统每天都在变得更强大。AnythingLLM 使其易于使用。</p><h3 id="下载anythingllm" tabindex="-1"><a class="header-anchor" href="#下载anythingllm"><span>下载AnythingLLM</span></a></h3><p>进入<a href="https://anythingllm.com/desktop" target="_blank" rel="noopener noreferrer">AnythingLLM</a>下载桌面版本。</p><p><img src="`+o+'" alt="AnythingLLM下载"></p><p>这里下载的是<code>Mac+M1</code>配置的版本，下载完成之后，直接安装。</p><h3 id="启动anythingllm" tabindex="-1"><a class="header-anchor" href="#启动anythingllm"><span>启动AnythingLLM</span></a></h3><p>启动后，点击<code>Get Started</code>。</p><p><img src="'+k+'" alt="AnythingLLM启动"></p><p>点击下一步</p><p><img src="'+c+'" alt="AnythingLLM开始"></p><p>点击下一步</p><p><img src="'+g+'" alt="AnythingLLM步骤一"></p><p>注册后，点击下一步</p><p><img src="'+A+'" alt="AnythingLLM步骤二"></p><p>输入工作空间名称后，点击下一步</p><p><img src="'+m+'" alt="AnythingLLM步骤三"></p><p>进入工作空间</p><p><img src="'+y+'" alt="AnythingLLM工作空间"></p><h3 id="设置" tabindex="-1"><a class="header-anchor" href="#设置"><span>设置</span></a></h3><h4 id="切换语言" tabindex="-1"><a class="header-anchor" href="#切换语言"><span>切换语言</span></a></h4><p>如果需要切换语言为英文，可以点击右下角设置按钮，将<code>Display Language</code>选项，切换为<code>Chinese</code>即可。</p><p><img src="'+B+'" alt="AnythingLLM设置"></p><h4 id="设置模型" tabindex="-1"><a class="header-anchor" href="#设置模型"><span>设置模型</span></a></h4><ol><li>展开人工智能提供商</li><li>选择LLM首选项</li><li>选择LLM提供商为Ollama</li><li>选择Ollama模型为<code>deepseek-r1:1.5b</code>，这根据自己的需要选择，<code>Max Tokens</code>保持默认的即可。</li><li>保存</li></ol><p><img src="'+L+'" alt="AnythingLLM设置模型"></p><h4 id="设置embedder" tabindex="-1"><a class="header-anchor" href="#设置embedder"><span>设置Embedder</span></a></h4><ol><li>展开人工智能提供商</li><li>选择Embadder首选项</li><li>选择嵌入引擎提供商为Ollama</li><li>选择Ollama模型为<code>modelscope.cn/Embedding-GGUF/nomic-embed-text-v1.5-GGUF</code>，这根据自己的需要选择，<code>Max Embedding Chunk Length</code>保持默认的即可。</li><li>保存</li></ol><p><img src="'+C+'" alt="AnythingLLM设置Embedder"></p><h4 id="工作区聊天设置" tabindex="-1"><a class="header-anchor" href="#工作区聊天设置"><span>工作区聊天设置</span></a></h4><ol><li>点击工作区名称右侧的设置按钮，<code>hover</code>状态可见</li><li>选择“聊天设置”</li><li>工作区LLM提供商选择<code>Ollama</code></li><li>工作区聊天模型选择<code>deepseek-r1:1.5b</code></li><li>点击底部的<code>Update workspace agent</code>更新</li></ol><p><img src="'+b+'" alt="AnythingLLM工作区聊天设置"></p><h4 id="工作区代理配置" tabindex="-1"><a class="header-anchor" href="#工作区代理配置"><span>工作区代理配置</span></a></h4><ol><li>点击工作区名称右侧的设置按钮，<code>hover</code>状态可见</li><li>选择“代理配置”</li><li>工作区LLM提供商选择<code>Ollama</code></li><li>工作区代理模型选择<code>deepseek-r1:1.5b</code></li><li>点击底部的<code>Update workspace agent</code>更新</li></ol><p><img src="'+E+`" alt="AnythingLLM工作区代理配置"></p><h3 id="使用" tabindex="-1"><a class="header-anchor" href="#使用"><span>使用</span></a></h3><p>在完成<code>设置</code>之后，我们就可以在工作空间中使用了。</p><div class="language-sh line-numbers-mode" data-ext="sh" data-title="sh"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">$</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ps</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> aux</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> |</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> grep</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ollama</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> |</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> grep</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -v</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> grep</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">matias</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">           97824</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">   0.0</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  0.1</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 412087456</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  20736</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   ??</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">  S</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">    五03下午</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   6:09.96</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> /Applications/Ollama.app/Contents/Resources/ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> serve</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">matias</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">           91216</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">   0.0</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">  6.6</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 413790288</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 1114192</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   ??</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">  S</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">    11:22上午</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">   0:02.22</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> /Applications/Ollama.app/Contents/Resources/ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> runner</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --model</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> /Users/matias/.ollama/models/blobs/sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --ctx-size</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 8192</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --batch-size</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 512</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --n-gpu-layers</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 29</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --threads</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 4</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --mlock</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --parallel</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 4</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --port</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 54831</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过上面的查询可以看到，当我们使用时，会启动<code>ollama</code>的<code>deepseek-r1:1.5b</code>模型为我们提供服</p><h3 id="投喂数据" tabindex="-1"><a class="header-anchor" href="#投喂数据"><span>投喂数据</span></a></h3><p>在投喂数据之前，我们先选择一份测试用的数据，支持PDF、Txt、Word、csv等格式。</p><ol><li>点击工作空间的上传按钮</li><li>选择或拖拽文件上传</li><li>选择已上传的文件，并点击<code>Move to workspace</code>添加到工作空间</li><li>再点击“Save and Embed”</li><li>然后就可以返回工作空间，对话了</li></ol><p>新建线程可以直接点击提示的<strong>upload a document</strong>上传文件。</p><p><img src="`+u+'" alt="AnythingLLM新建线程"></p><p><img src="'+v+'" alt="AnythingLLM进入上传"></p><p><img src="'+M+'" alt="AnythingLLM测试"></p><p>从回答的思考中，我们可以看到是引用了我们提供的上下文的。</p><p><strong>注意</strong> 感觉<code>1.5B</code>的效果还是不行，后续可以尝试<code>7B</code>的模型。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><p><a href="https://modelscope.cn/docs/models/advanced-usage/ollama-integration" target="_blank" rel="noopener noreferrer">Ollama加载ModelScope模型</a></p><p><a href="https://anythingllm.com/desktop" target="_blank" rel="noopener noreferrer">AnythingLLM</a></p>',62))])}const F=e(D,[["render",f],["__file","5roawtc8.html.vue"]]),O=JSON.parse('{"path":"/llm/anythingllm/5roawtc8.html","title":"AnythingLLM 接入RAG","lang":"zh-CN","frontmatter":{"title":"AnythingLLM 接入RAG","createTime":"2025/02/10 14:49:56","permalink":"/llm/anythingllm/5roawtc8.html","watermark":true},"headers":[],"readingTime":{"minutes":4.76,"words":1427},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/anythingllm/AnythingLLM接入RAG.md","bulletin":false}');export{F as comp,O as data};
