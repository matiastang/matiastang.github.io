import{_ as t,c as l,a,o as r}from"./app-CS9K37Kg.js";const n={};function o(i,e){return r(),l("div",null,e[0]||(e[0]=[a('<p>今天（2025-03-06）Qwen更新了新模型QwQ-32B。QwQ 是 Qwen 系列中的推理模型。与传统的指令调优模型相比，具备思考和推理能力的 QwQ 在下游任务中，特别是在解决难题时，能够显著提升性能。QwQ-32B 是一个中等规模的推理模型，其性能可以与最先进的推理模型相媲美，例如 DeepSeek-R1、o1-mini。</p><p>此仓库包含 QwQ 32B 模型，具有以下特点：</p><ul><li>类型：因果语言模型</li><li>训练阶段：预训练及后训练（监督微调和强化学习）</li><li>架构：带有 RoPE、SwiGLU、RMSNorm 和 Attention QKV 偏置的 transformers</li><li>参数数量：325 亿</li><li>非嵌入参数数量：310 亿</li><li>层数：64 层</li><li>注意力头数（GQA）：Q 为 40 个，KV 为 8 个</li><li>上下文长度：完整支持 131,072 个 tokens</li></ul><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><p><a href="https://modelscope.cn/models/Qwen/QwQ-32B" target="_blank" rel="noopener noreferrer">QwQ-32B</a></p><p><a href="https://qwenlm.github.io/zh/blog/qwen2.5/" target="_blank" rel="noopener noreferrer">Qwen2.5: 基础模型大派对！</a></p><p><a href="https://modelscope.cn/collections/QwQ-32B-0f1806b8a8514a" target="_blank" rel="noopener noreferrer">QwQ-32B 模型集</a></p>',7)]))}const m=t(n,[["render",o],["__file","qxbftl1v.html.vue"]]),p=JSON.parse('{"path":"/llm/qwen/qxbftl1v.html","title":"QwQ-32B","lang":"zh-CN","frontmatter":{"title":"QwQ-32B","createTime":"2025/03/06 10:23:29","permalink":"/llm/qwen/qxbftl1v.html","watermark":true},"headers":[],"readingTime":{"minutes":0.9,"words":271},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/llm/qwen/QwQ-32B.md","bulletin":false}');export{m as comp,p as data};
