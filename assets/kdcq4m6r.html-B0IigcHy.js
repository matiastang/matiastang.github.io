import{_ as d,c as o,a as e,o as r}from"./app-CS9K37Kg.js";const a={};function n(s,t){return r(),o("div",null,t[0]||(t[0]=[e('<p><strong>分词（Tokenization）<strong>还有个配对的名词叫</strong>逆分词（Detokenization）</strong>，可以理解为NLP的神经网络模型输入前对于<strong>输入和输出的标准化</strong>。</p><h2 id="分词" tabindex="-1"><a class="header-anchor" href="#分词"><span>分词</span></a></h2><p>分词（Tokenization）是自然语言处理（NLP）中的一个基本步骤，它将文本字符串分解为更小的单元，称为标记（tokens）。这些标记可以是单词、短语、字符或符号，具体取决于所使用的分词方法。</p><h3 id="分词类型" tabindex="-1"><a class="header-anchor" href="#分词类型"><span>分词类型</span></a></h3><p>分词的主要目的是将文本转换为计算机可以处理的形式，以便进行进一步的分析和处理。分词方法有很多种，包括但不限于以下几种：</p><ol><li><strong>空格分词</strong>：这是最简单的一种分词方法，它将文本按照空格进行分割。例如，&quot;Hello world&quot;会被分割为两个标记：&quot;Hello&quot;和&quot;world&quot;。</li><li><strong>字符分词</strong>：这种方法将文本按照字符进行分割。例如，&quot;Hello world&quot;会被分割为七个标记：&quot;H&quot;、&quot;e&quot;、&quot;l&quot;、&quot;l&quot;、&quot;o&quot;、&quot; &quot;和&quot;w&quot;。</li><li><strong>语义分词</strong>：这种方法考虑了单词的语义，将文本按照语义单元进行分割。例如，&quot;I love cats and dogs&quot;会被分割为四个标记：&quot;I&quot;、&quot;love&quot;、&quot;cats&quot;、&quot;and&quot;、&quot;dogs&quot;。</li></ol><table><thead><tr><th>方法</th><th>适用语言</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>空格分词</td><td>英文等</td><td>简单快速</td><td>无法处理连字符、标点</td></tr><tr><td>正则分词</td><td>英文、部分语言</td><td>可去除标点</td><td>规则需要手动设计</td></tr><tr><td>词典分词</td><td>中文、日文</td><td>速度快，效果较好</td><td>依赖词库，难处理 OOV</td></tr><tr><td>统计分词</td><td>中文、日文</td><td>能处理 OOV</td><td>需要训练数据</td></tr><tr><td>子词分词</td><td>多种语言</td><td>适用于 Transformer</td><td>需训练子词模型</td></tr><tr><td>字符分词</td><td>适用于所有语言</td><td>适合低资源环境</td><td>token 过多，难以捕捉语义</td></tr><tr><td>语义分词</td><td>所有语言</td><td>结合上下文，准确率高</td><td>需要深度学习模型</td></tr></tbody></table><h3 id="分词算法" tabindex="-1"><a class="header-anchor" href="#分词算法"><span>分词算法</span></a></h3><p>LLM 已经扩展了处理多语言和多模式输入的能力，为了适应这些数据的多样性，已经开发了专门的<strong>tokenization</strong>方法。通过利用特定语言的token或子词技术，多语言标记在一个模型中处理多种语言。多模态标记将文本与其他模式(如图像或音频)结合起来，使用融合或连接等技术来有效地表示不同的数据源。</p><table><thead><tr><th>算法</th><th>适用语言</th><th>优点</th><th>缺点</th><th>代表模型</th></tr></thead><tbody><tr><td>Byte Pair Encoding（BPE）</td><td>多语言</td><td>速度快，效果较好</td><td>需要训练数据</td><td>GPT、GPT-2、GPT-J、GPT-Neo、RoBERTa、BART、LLaMA、ChatGLM-6B、Baichuan</td></tr><tr><td>WordPiece</td><td>多语言</td><td>速度快，效果较好</td><td>需要训练数据</td><td>BERT、DistilBERT、MobileBERT</td></tr><tr><td>SentencePiece</td><td>多语言</td><td>速度快，效果较好</td><td>需要训练数据</td><td>GPT-3、GPT-4、T5、mT5、BART、mBART、ALBERT、BLOOM、LLaMA</td></tr><tr><td>Unigram</td><td>多语言</td><td>速度快，效果较好</td><td>需要训练数据</td><td>AIBERT、T5、mBART、XLNet</td></tr></tbody></table><p>不同的平台的token算法都不一样，甚至不同的模型的token数量也未必一致。</p><p>在<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">OpenAI Tokenizer</a>中可以查看一些模型的token拆分情况。</p><h2 id="逆分词" tabindex="-1"><a class="header-anchor" href="#逆分词"><span>逆分词</span></a></h2>',13)]))}const h=d(a,[["render",n],["__file","kdcq4m6r.html.vue"]]),l=JSON.parse('{"path":"/ai/kdcq4m6r.html","title":"Token","lang":"zh-CN","frontmatter":{"title":"Token","createTime":"2025/03/25 14:35:15","permalink":"/ai/kdcq4m6r.html","watermark":true},"headers":[],"readingTime":{"minutes":2.65,"words":796},"git":{"updatedTime":1755670488000,"contributors":[{"name":"唐道勇","username":"唐道勇","email":"matias@tangdaoyongdeMacBook-Pro.local","commits":1,"avatar":"https://avatars.githubusercontent.com/唐道勇?v=4","url":"https://github.com/唐道勇"}]},"filePathRelative":"notes/ai/Token.md","bulletin":false}');export{h as comp,l as data};
